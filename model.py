# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WWdvuKNshv3GWZeHh_BLpCRP7BrTMEk9
"""

from google.colab import drive
drive.mount('/content/drive')

import os
from keras.preprocessing import image
import matplotlib.pyplot as plt 
import numpy as np
from keras.utils.np_utils import to_categorical
import random,shutil
from keras.models import Sequential
from keras.layers import Dropout,Conv2D,Flatten,Dense, MaxPooling2D, BatchNormalization
from keras.models import load_model
from keras.preprocessing.image import ImageDataGenerator

data_gen = image.ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2,
)

train_generator = data_gen.flow_from_directory(
    '/content/drive/MyDrive/train',
    target_size=(74, 74),
    batch_size=32,
    class_mode='categorical',
    shuffle=True,
    subset='training',
    color_mode='grayscale',
    seed=17
)

val_generator = data_gen.flow_from_directory(
    '/content/drive/MyDrive/train',
    target_size=(74, 74),
    batch_size=32,
    class_mode='categorical',
    shuffle=True,
    subset='validation',
    color_mode='grayscale',
    seed=17
)

BS= 32
TS=(74,74)
SPE= len(train_generator.classes)//BS
VS = len(val_generator.classes)//BS
print(SPE,VS)

model = Sequential([
    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(74,74,1)),
    MaxPooling2D(pool_size=(1,1)),
    Conv2D(32,(3,3),activation='relu'),
    MaxPooling2D(pool_size=(1,1)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(pool_size=(1,1)),
    Dropout(0.25),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(2, activation='softmax')
])

model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])
epochs = 15

history = model.fit_generator(train_generator, validation_data=val_generator,epochs=15,steps_per_epoch=SPE ,validation_steps=VS)

model.save('models/harshali.h5', overwrite=True)

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(epochs)

plt.figure(figsize=(10, 4))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.figure(figsize=(10, 4))
plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()